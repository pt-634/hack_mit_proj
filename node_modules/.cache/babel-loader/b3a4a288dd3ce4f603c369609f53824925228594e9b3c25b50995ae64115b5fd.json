{"ast":null,"code":"'use strict';\n\n// File generated from our OpenAPI spec by Stainless.\nObject.defineProperty(exports, '__esModule', {\n  value: true\n});\nexports.Transcriptions = void 0;\nconst resource_1 = require('openai/resource');\nconst core_1 = require('openai/core');\nclass Transcriptions extends resource_1.APIResource {\n  /**\n   * Transcribes audio into the input language.\n   */\n  create(body, options) {\n    return this.post('/audio/transcriptions', (0, core_1.multipartFormRequestOptions)({\n      body,\n      ...options\n    }));\n  }\n}\nexports.Transcriptions = Transcriptions;\n(function (Transcriptions) {})(Transcriptions = exports.Transcriptions || (exports.Transcriptions = {}));","map":{"version":3,"names":["resource_1","require","core_1","Transcriptions","APIResource","create","body","options","post","multipartFormRequestOptions","exports"],"sources":["C:\\Users\\seanm\\Desktop\\hackmit\\node_modules\\openai\\src\\resources\\audio\\transcriptions.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless.\n\nimport * as Core from '../../core';\nimport { APIResource } from '../../resource';\nimport * as API from './index';\nimport { type Uploadable, multipartFormRequestOptions } from '../../core';\n\nexport class Transcriptions extends APIResource {\n  /**\n   * Transcribes audio into the input language.\n   */\n  create(body: TranscriptionCreateParams, options?: Core.RequestOptions): Core.APIPromise<Transcription> {\n    return this.post('/audio/transcriptions', multipartFormRequestOptions({ body, ...options }));\n  }\n}\n\nexport interface Transcription {\n  text: string;\n}\n\nexport interface TranscriptionCreateParams {\n  /**\n   * The audio file object (not file name) to transcribe, in one of these formats:\n   * flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Uploadable;\n\n  /**\n   * ID of the model to use. Only `whisper-1` is currently available.\n   */\n  model: (string & {}) | 'whisper-1';\n\n  /**\n   * The language of the input audio. Supplying the input language in\n   * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will\n   * improve accuracy and latency.\n   */\n  language?: string;\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the\n   * audio language.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the transcript output, in one of these options: json, text, srt,\n   * verbose_json, or vtt.\n   */\n  response_format?: 'json' | 'text' | 'srt' | 'verbose_json' | 'vtt';\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n}\n\nexport namespace Transcriptions {\n  export import Transcription = API.Transcription;\n  export import TranscriptionCreateParams = API.TranscriptionCreateParams;\n}\n"],"mappings":";;AAAA;;;;;AAGA,MAAAA,UAAA,GAAAC,OAAA;AAEA,MAAAC,MAAA,GAAAD,OAAA;AAEA,MAAaE,cAAe,SAAQH,UAAA,CAAAI,WAAW;;;;QAI7CC,CAAAC,IAAO,EAA+BC,OAAE,EAA6B;WACnE,IAAO,CAAAC,IAAK,wBAAK,IAAuB,EAAEN,MAAA,CAAAO,2BAAA;MAA2BH,IAAG;MAAA,GAAIC;IAAK,GAAO;;;AAL5FG,OAAA,CAAAP,cAAA,GAAAA,cAAA;AAuDA,WAAiBA,cAAc,MAAAA,cAAA,GAAAO,OAAA,CAAAP,cAAA,KAAAO,OAAA,CAAAP,cAAA"},"metadata":{},"sourceType":"script","externalDependencies":[]}